{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import metrics \n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "import random \n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "keras               2.10.0\n",
       "keras_tuner         1.1.3\n",
       "numpy               1.23.1\n",
       "pandas              1.4.4\n",
       "session_info        1.0.0\n",
       "sklearn             1.1.3\n",
       "tensorflow          2.10.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42    NA\n",
       "absl                                        NA\n",
       "asttokens                                   NA\n",
       "astunparse                                  1.6.3\n",
       "backcall                                    0.2.0\n",
       "certifi                                     2022.09.24\n",
       "charset_normalizer                          2.1.1\n",
       "colorama                                    0.4.6\n",
       "cython_runtime                              NA\n",
       "dateutil                                    2.8.2\n",
       "debugpy                                     1.6.3\n",
       "decorator                                   5.1.1\n",
       "entrypoints                                 0.4\n",
       "executing                                   1.2.0\n",
       "flatbuffers                                 22.10.26\n",
       "gast                                        NA\n",
       "google                                      NA\n",
       "grpc                                        1.50.0\n",
       "h5py                                        3.7.0\n",
       "idna                                        3.4\n",
       "ipykernel                                   6.17.0\n",
       "jedi                                        0.18.1\n",
       "joblib                                      1.2.0\n",
       "nt                                          NA\n",
       "opt_einsum                                  v3.3.0\n",
       "packaging                                   21.3\n",
       "parso                                       0.8.3\n",
       "pickleshare                                 0.7.5\n",
       "pkg_resources                               NA\n",
       "prompt_toolkit                              3.0.32\n",
       "psutil                                      5.9.4\n",
       "pure_eval                                   0.2.2\n",
       "pydev_ipython                               NA\n",
       "pydevconsole                                NA\n",
       "pydevd                                      2.8.0\n",
       "pydevd_file_utils                           NA\n",
       "pydevd_plugins                              NA\n",
       "pydevd_tracing                              NA\n",
       "pygments                                    2.13.0\n",
       "pytz                                        2022.6\n",
       "pywin32_bootstrap                           NA\n",
       "pywin32_system32                            NA\n",
       "requests                                    2.28.1\n",
       "scipy                                       1.9.3\n",
       "six                                         1.16.0\n",
       "stack_data                                  0.6.0\n",
       "tensorboard                                 2.10.1\n",
       "termcolor                                   NA\n",
       "threadpoolctl                               3.1.0\n",
       "tornado                                     6.2\n",
       "traitlets                                   5.5.0\n",
       "typing_extensions                           NA\n",
       "urllib3                                     1.26.12\n",
       "wcwidth                                     0.2.5\n",
       "wrapt                                       1.14.1\n",
       "zmq                                         24.0.1\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.6.0\n",
       "jupyter_client      7.4.4\n",
       "jupyter_core        4.11.2\n",
       "-----\n",
       "Python 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n",
       "Windows-10-10.0.19044-SP0\n",
       "-----\n",
       "Session information updated at 2022-11-09 18:17\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#German dataset\n",
    "def German():\n",
    "    df = pd.read_table(os.path.join(\"datasets\",\"german.data-numeric.txt\"),delim_whitespace = True, header = None)\n",
    "#     display(df.head())\n",
    "    X = df.drop(columns = [24])\n",
    "    y = df[24]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED) # 70% training and 30% test\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    print(\"Grid searching best parameters for decision tree\")\n",
    "    param_grid = { \n",
    "        'criterion': ['gini','entropy'],\n",
    "        'splitter': ['best','random'],\n",
    "        'max_features': ['sqrt','log2'],\n",
    "        'max_depth':list(range(1,10))\n",
    "    }\n",
    "\n",
    "    # grid search for best parameters\n",
    "    \n",
    "    grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv= 3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    # Create Decision Tree classifer object\n",
    "    clf = DecisionTreeClassifier(criterion = best_params['criterion'],splitter = best_params['splitter'], \n",
    "    max_features = best_params['max_features'], max_depth = best_params['max_depth'], random_state=SEED)\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    f = metrics.f1_score(y_test, y_pred)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy for decision tree:\", acc)\n",
    "    print(\"F-score for decision tree:\", f)\n",
    "    print(\"\\n\")\n",
    "    return acc, f, best_params\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ramdom forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(X_train, X_test, y_train, y_test):\n",
    "    print(\"Grid searching best parameters for random forest\")\n",
    "    param_grid = {'n_estimators': list(range(800, 1600, 200)),\n",
    "               'max_depth': list(range(10,110,10)),\n",
    "               'min_samples_split': [2,5,10],\n",
    "               'min_samples_leaf': [1,2,4],\n",
    "               'bootstrap': [True, False]}\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    grid_search = RandomizedSearchCV(RandomForestClassifier(), param_grid, cv= 3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators = best_params['n_estimators'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        min_samples_split = best_params['min_samples_split'], \n",
    "        min_samples_leaf=best_params['min_samples_leaf'],\n",
    "        bootstrap=best_params['bootstrap'],\n",
    "        random_state = SEED)\n",
    "    # Train the model on training data\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    # Use the forest's predict method on the test data\n",
    "    y_pred = rf.predict(X_test)\n",
    "    f = metrics.f1_score(y_test, y_pred)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy for random forest:\", acc)\n",
    "    print(\"Best F-score for random forest:\",f)\n",
    "    print(\"\\n\")\n",
    "    return acc, f, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    print(\"Grid searching best parameters for SVM\")\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "        'gamma' : [0.05, 0.1, 0.15, 0.20, 0.25], \n",
    "        'degree' : list(range(1,7)), \n",
    "        'kernel' : ['rbf', 'linear', 'poly','sigmoid']\n",
    "        }\n",
    "    \n",
    "    grid_search = RandomizedSearchCV(svm.SVC(), param_grid, cv = 3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    #Create a svm Classifier\n",
    "    clf = svm.SVC(\n",
    "        C=best_params['C'],\n",
    "        gamma=best_params['gamma'],\n",
    "        degree=best_params['degree'],\n",
    "        kernel=best_params['kernel'],\n",
    "        random_state = SEED) # Linear Kernel\n",
    "    #Train the model using the training sets\n",
    "    clf.fit(X_train, y_train)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    f = metrics.f1_score(y_test, y_pred)\n",
    "#         print(\"kernel\", i)\n",
    "#         print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "#         print(\"F-score:\",f)\n",
    "\n",
    "    print(\"Accuracy for svm:\",acc)\n",
    "    print(\"Best F-score for svm:\",f)\n",
    "    print(\"\\n\")\n",
    "    return acc, f, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(hp):\n",
    "    dr = 0.2 #dropout rate\n",
    "    no_neurons_1 = hp.Float('no_neurons_1', 32, 256, step=32)\n",
    "\n",
    "    rate = hp.Float('learning_rate', 0.001, 0.5, sampling=\"log\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(no_neurons_1, input_shape = (X_train.shape[1],), activation = \"relu\"),    # not sure if it is best practice\n",
    "        Dropout(rate = dr),\n",
    "        Dense(1, activation = \"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer = keras.optimizers.SGD(learning_rate = rate),\n",
    "                  loss = \"binary_crossentropy\",\n",
    "                  metrics = [\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(n,l, X_train, X_test, y_train, y_test):\n",
    "    dr = 0.2 #dropout rate\n",
    "    early_stopping = EarlyStopping(monitor = \"val_loss\", patience = 3)\n",
    "    max_epochs = 100 #number of maximum epochs\n",
    "    batch = 64 #batch size\n",
    "\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(n, input_shape = (X_train.shape[1],), activation = \"relu\"),\n",
    "        Dropout(rate = dr),\n",
    "        Dense(1, activation = \"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer = keras.optimizers.SGD(learning_rate = l),\n",
    "                  loss = \"binary_crossentropy\",\n",
    "                  metrics = [\"accuracy\"]\n",
    "    )\n",
    "    model.fit(X_train, y_train,\n",
    "             validation_data=(X_test, y_test),\n",
    "             batch_size = batch,\n",
    "             epochs = max_epochs,\n",
    "             verbose = 0, \n",
    "             callbacks = [early_stopping])\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    f = metrics.f1_score(y_test, y_pred)\n",
    "    print(\"Accuracy for neural network:\",acc)\n",
    "    print(\"Best F-score for neural network:\",f)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return acc, f, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(X_train, X_test, y_train, y_test):\n",
    "    tuner = kt.RandomSearch(\n",
    "        model,\n",
    "        objective=\"val_accuracy\",\n",
    "        max_trials=10,\n",
    "        overwrite=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor = \"val_loss\", patience = 3)\n",
    "    max_epochs = 100 #number of maximum epochs\n",
    "    batch = 64 #batch size\n",
    "\n",
    "    tuner.search(X_train, y_train,\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 batch_size = batch,\n",
    "                 epochs = max_epochs,\n",
    "                 verbose = 0, \n",
    "                 callbacks = [early_stopping])\n",
    "\n",
    "    n = tuner.get_best_hyperparameters()[0].get(\"no_neurons_1\")\n",
    "    l = tuner.get_best_hyperparameters()[0].get(\"learning_rate\")\n",
    "\n",
    "    return best_model(n,l, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_models(X_train, X_test, y_train, y_test):\n",
    "    acc_dt, f_dt, best_params_dt = DT(X_train, X_test, y_train, y_test)\n",
    "    acc_rf, f_rf, best_params_rf = RF(X_train, X_test, y_train, y_test)\n",
    "    acc_svm, f_svm, best_params_svm = SVM(X_train, X_test, y_train, y_test)\n",
    "    acc_nn, f_nn, best_params_nn = NN(X_train, X_test, y_train, y_test)\n",
    "    return {\n",
    "        'model':['decision tree', 'random forest', 'svm', 'neural network'],\n",
    "        'accuracy':[acc_dt, acc_rf, acc_svm, acc_nn],\n",
    "        'f1_score':[f_dt, f_rf, f_svm, f_nn],\n",
    "        'model_parameters':[best_params_dt, best_params_rf, best_params_svm, best_params_nn]\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid searching best parameters for decision tree\n",
      "Accuracy for decision tree: 0.6866666666666666\n",
      "F-score for decision tree: 0.7991452991452991\n",
      "\n",
      "\n",
      "Grid searching best parameters for random forest\n",
      "Accuracy for random forest: 0.76\n",
      "Best F-score for random forest: 0.8461538461538461\n",
      "\n",
      "\n",
      "Grid searching best parameters for SVM\n"
     ]
    }
   ],
   "source": [
    "#German dataset\n",
    "X_train, X_test, y_train, y_test = German()\n",
    "german_model_score = run_all_models(X_train, X_test, y_train, y_test)\n",
    "german_model_score['dataset'] = ['german']*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b181fbedbc45c428172ad2d3d921732af5f9721e7dc8d85197bc3988ec89914"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
