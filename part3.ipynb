{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import metrics \n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "import random \n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing method\n",
    "def cat_2_num(df:pd.DataFrame):\n",
    "    cat_columns = df.select_dtypes(['object']).columns\n",
    "    df[cat_columns] = df[cat_columns].astype('category')\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#German dataset\n",
    "def German():\n",
    "    df = pd.read_table(os.path.join(\"datasets\",\"german.data-numeric.txt\"),delim_whitespace = True, header = None)\n",
    "    return train_test_split(df.drop(columns = [24]), df[24], test_size=0.3, random_state=SEED, stratify=df[24]) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Australian():\n",
    "    df = pd.read_table(os.path.join(\"datasets\",\"australian.dat\"),delim_whitespace = True, header = None)\n",
    "    return train_test_split(df.drop(columns = [14]), df[14], test_size=0.3, random_state=SEED, stratify=df[14]) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crx():\n",
    "    df = pd.read_csv(os.path.join(\"datasets\",\"crx.data\"), header = None)\n",
    "    # drop entries with ?\n",
    "    df = df.replace(\"?\", np.nan).dropna()\n",
    "    # convert category data to numerical data\n",
    "    df = cat_2_num(df)\n",
    "    return train_test_split(df.drop(columns = [15]), df[15], test_size=0.3, random_state=SEED, stratify=df[15]) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Horse():\n",
    "    df = pd.read_table(os.path.join(\"datasets\",\"horse-colic.data\"), delim_whitespace=True, header = None)\n",
    "    # instead of dropna, treat '?' as a separate class. reason: drop would leave only 68 entries\n",
    "    df = cat_2_num(df)\n",
    "\n",
    "    df_test = pd.read_table(os.path.join(\"datasets\",\"horse-colic.test\"), delim_whitespace=True, header = None)\n",
    "    df_test = cat_2_num(df_test)\n",
    "    return df.drop(columns = [24]), df_test.drop(columns = [24]), df[24], df_test[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vehicle():\n",
    "    vehicles_dfs = [pd.read_table(os.path.join(\"datasets\",f), delim_whitespace=True, header = None) for f in os.listdir('datasets') if f.startswith('xa')]\n",
    "    df = pd.concat(vehicles_dfs)\n",
    "    df.replace(\"?\", np.nan).notna()\n",
    "    df = cat_2_num(df)\n",
    "    return train_test_split(df.drop(columns = [18]), df[18], test_size=0.3, random_state=SEED, stratify=df[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pumpkin():\n",
    "    df = pd.read_excel(os.path.join(\"datasets\",'Pumpkin_Seeds_Dataset.xlsx'), sheet_name='Pumpkin_Seeds_Dataset',engine='openpyxl')\n",
    "    df = cat_2_num(df)\n",
    "    return train_test_split(df.drop(columns = ['Class']), df['Class'], test_size=0.3, random_state=SEED, stratify=df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Water():\n",
    "    df = pd.read_csv(os.path.join(\"datasets\",'water_potability.csv'))\n",
    "    df = df.dropna()\n",
    "    return train_test_split(df.drop(columns = ['Potability']), df['Potability'].astype(bool), test_size=0.3, random_state=SEED, stratify=df['Potability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Banking():\n",
    "    df = pd.read_csv(os.path.join(\"datasets\",'banking.csv'))\n",
    "    df = df.dropna()\n",
    "    df = cat_2_num(df)\n",
    "    # random sample by class ( balance out data )\n",
    "    g = df.groupby('y')\n",
    "    df = g.apply(lambda x: x.sample(1500).reset_index(drop=True))\n",
    "    return train_test_split(df.drop(columns = ['y']), df['y'].astype(bool), test_size=0.3, random_state=SEED, stratify=df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    print(\"Grid searching best parameters for decision tree\")\n",
    "    param_grid = { \n",
    "        'criterion': ['gini','entropy'],\n",
    "        'splitter': ['best','random'],\n",
    "        'max_features': ['sqrt','log2'],\n",
    "        'max_depth':list(range(1,10))\n",
    "    }\n",
    "\n",
    "    # grid search for best parameters\n",
    "    \n",
    "    grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv= 3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    # Create Decision Tree classifer object\n",
    "    clf = DecisionTreeClassifier(criterion = best_params['criterion'],splitter = best_params['splitter'], \n",
    "    max_features = best_params['max_features'], max_depth = best_params['max_depth'], random_state=SEED)\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    f = metrics.f1_score(y_test, y_pred)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy for decision tree:\", acc)\n",
    "    print(\"F-score for decision tree:\", f)\n",
    "    print(\"==============================================================\")\n",
    "    return acc, f, best_params\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ramdom forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(X_train, X_test, y_train, y_test):\n",
    "    print(\"Random searching best parameters for random forest\")\n",
    "    param_grid = {'n_estimators': list(range(800, 1600, 200)),\n",
    "               'max_depth': list(range(10,110,10)),\n",
    "               'min_samples_split': [2,5,10],\n",
    "               'min_samples_leaf': [1,2,4],\n",
    "               'bootstrap': [True, False]}\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    grid_search = RandomizedSearchCV(RandomForestClassifier(), param_grid, cv= 3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators = best_params['n_estimators'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        min_samples_split = best_params['min_samples_split'], \n",
    "        min_samples_leaf=best_params['min_samples_leaf'],\n",
    "        bootstrap=best_params['bootstrap'],\n",
    "        random_state = SEED)\n",
    "    # Train the model on training data\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    # Use the forest's predict method on the test data\n",
    "    y_pred = rf.predict(X_test)\n",
    "    f = metrics.f1_score(y_test, y_pred)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy for random forest:\", acc)\n",
    "    print(\"Best F-score for random forest:\",f)\n",
    "    print(\"==============================================================\")\n",
    "    return acc, f, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    print(\"Random searching best parameters for SVM\")\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "        'kernel' : ['rbf', 'linear', 'poly','sigmoid']\n",
    "        }\n",
    "    \n",
    "    grid_search = RandomizedSearchCV(svm.SVC(), param_grid, cv = 3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    #Create a svm Classifier\n",
    "    clf = svm.SVC(\n",
    "        C=best_params['C'],\n",
    "        kernel=best_params['kernel'],\n",
    "        random_state = SEED) # Linear Kernel\n",
    "    #Train the model using the training sets\n",
    "    clf.fit(X_train, y_train)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    f = metrics.f1_score(y_test, y_pred)\n",
    "#         print(\"kernel\", i)\n",
    "#         print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "#         print(\"F-score:\",f)\n",
    "\n",
    "    print(\"Accuracy for svm:\",acc)\n",
    "    print(\"Best F-score for svm:\",f)\n",
    "    print(\"==========================================\")\n",
    "    return acc, f, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(hp):\n",
    "    dr = 0.2 #dropout rate\n",
    "    no_neurons_1 = hp.Float('no_neurons_1', 32, 256, step=32)\n",
    "\n",
    "    rate = hp.Float('learning_rate', 0.001, 0.5, sampling=\"log\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(no_neurons_1, input_shape = (X_train.shape[1],), activation = \"relu\"),    # not sure if it is best practice\n",
    "        Dropout(rate = dr),\n",
    "        Dense(1, activation = \"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer = keras.optimizers.SGD(learning_rate = rate),\n",
    "                  loss = \"binary_crossentropy\",\n",
    "                  metrics = [\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(n,l, X_train, X_test, y_train, y_test):\n",
    "    dr = 0.2 #dropout rate\n",
    "    early_stopping = EarlyStopping(monitor = \"val_loss\", patience = 3)\n",
    "    max_epochs = 100 #number of maximum epochs\n",
    "    batch = 64 #batch size\n",
    "\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(n, input_shape = (X_train.shape[1],), activation = \"relu\"),\n",
    "        Dropout(rate = dr),\n",
    "        Dense(1, activation = \"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer = keras.optimizers.SGD(learning_rate = l),\n",
    "                  loss = \"binary_crossentropy\",\n",
    "                  metrics = [\"accuracy\"]\n",
    "    )\n",
    "    model.fit(X_train, y_train,\n",
    "             validation_data=(X_test, y_test),\n",
    "             batch_size = batch,\n",
    "             epochs = max_epochs,\n",
    "             verbose = 0, \n",
    "             callbacks = [early_stopping])\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    f = metrics.f1_score(y_test, y_pred)\n",
    "    print(\"Accuracy for neural network:\",acc)\n",
    "    print(\"Best F-score for neural network:\",f)\n",
    "    print(\"==============================================================\")\n",
    "    \n",
    "    return acc, f, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(X_train, X_test, y_train, y_test):\n",
    "    tuner = kt.RandomSearch(\n",
    "        model,\n",
    "        objective=\"val_accuracy\",\n",
    "        max_trials=10,\n",
    "        overwrite=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor = \"val_loss\", patience = 3)\n",
    "    max_epochs = 100 #number of maximum epochs\n",
    "    batch = 64 #batch size\n",
    "\n",
    "    tuner.search(X_train, y_train,\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 batch_size = batch,\n",
    "                 epochs = max_epochs,\n",
    "                 verbose = 0, \n",
    "                 callbacks = [early_stopping])\n",
    "\n",
    "    n = tuner.get_best_hyperparameters()[0].get(\"no_neurons_1\")\n",
    "    l = tuner.get_best_hyperparameters()[0].get(\"learning_rate\")\n",
    "\n",
    "    return best_model(n,l, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_models(X_train, X_test, y_train, y_test):\n",
    "    acc_dt, f_dt, best_params_dt = DT(X_train, X_test, y_train, y_test)\n",
    "    acc_rf, f_rf, best_params_rf = RF(X_train, X_test, y_train, y_test)\n",
    "    acc_svm, f_svm, best_params_svm = SVM(X_train, X_test, y_train, y_test)\n",
    "    acc_nn, f_nn, best_params_nn = NN(X_train, X_test, y_train, y_test)\n",
    "    return {\n",
    "        'model':['decision tree', 'random forest', 'svm', 'neural network'],\n",
    "        'accuracy':[acc_dt, acc_rf, acc_svm, acc_nn],\n",
    "        'f1_score':[f_dt, f_rf, f_svm, f_nn],\n",
    "        'model_parameters':[best_params_dt, best_params_rf, best_params_svm, best_params_nn]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = Australian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    268\n",
       "1    215\n",
       "Name: 14, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()\n",
    "NN(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "10/10 [==============================] - 0s 767us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [38], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# for testing only\u001b[39;00m\n\u001b[0;32m      2\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m German()\n\u001b[1;32m----> 3\u001b[0m NN(X_train, X_test, y_train, y_test)\n",
      "Cell \u001b[1;32mIn [17], line 22\u001b[0m, in \u001b[0;36mNN\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     19\u001b[0m n \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_hyperparameters()[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mno_neurons_1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m l \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_hyperparameters()[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m \u001b[39mreturn\u001b[39;00m best_model(n,l, X_train, X_test, y_train, y_test)\n",
      "Cell \u001b[1;32mIn [37], line 25\u001b[0m, in \u001b[0;36mbest_model\u001b[1;34m(n, l, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     17\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train,\n\u001b[0;32m     18\u001b[0m          validation_data\u001b[39m=\u001b[39m(X_test, y_test),\n\u001b[0;32m     19\u001b[0m          batch_size \u001b[39m=\u001b[39m batch,\n\u001b[0;32m     20\u001b[0m          epochs \u001b[39m=\u001b[39m max_epochs,\n\u001b[0;32m     21\u001b[0m          verbose \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \n\u001b[0;32m     22\u001b[0m          callbacks \u001b[39m=\u001b[39m [early_stopping])\n\u001b[0;32m     24\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 25\u001b[0m \u001b[39mprint\u001b[39m(pd\u001b[39m.\u001b[39;49mSeries(y_pred)\u001b[39m.\u001b[39mvalue_counts())\n\u001b[0;32m     26\u001b[0m acc \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39maccuracy_score(y_test, y_pred)\n\u001b[0;32m     27\u001b[0m f \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mf1_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\GitHub\\CZ4032-Project2\\venv\\lib\\site-packages\\pandas\\core\\series.py:451\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    449\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    450\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m     data \u001b[39m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[0;32m    453\u001b[0m     manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mmode.data_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    454\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\GitHub\\CZ4032-Project2\\venv\\lib\\site-packages\\pandas\\core\\construction.py:601\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[0;32m    598\u001b[0m             subarr \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, subarr)\n\u001b[0;32m    599\u001b[0m             subarr \u001b[39m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[1;32m--> 601\u001b[0m subarr \u001b[39m=\u001b[39m _sanitize_ndim(subarr, data, dtype, index, allow_2d\u001b[39m=\u001b[39;49mallow_2d)\n\u001b[0;32m    603\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(subarr, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m    604\u001b[0m     \u001b[39m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[0;32m    605\u001b[0m     dtype \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mdtype, dtype)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\GitHub\\CZ4032-Project2\\venv\\lib\\site-packages\\pandas\\core\\construction.py:652\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[39mif\u001b[39;00m allow_2d:\n\u001b[0;32m    651\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m--> 652\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mData must be 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    653\u001b[0m \u001b[39mif\u001b[39;00m is_object_dtype(dtype) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m    654\u001b[0m     \u001b[39m# i.e. PandasDtype(\"O\")\u001b[39;00m\n\u001b[0;32m    656\u001b[0m     result \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39masarray_tuplesafe(data, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "# for testing only\n",
    "X_train, X_test, y_train, y_test = German()\n",
    "NN(X_train, X_test, y_train, y_test)\n",
    "# all prediction value is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dataset: German\n",
      "=========== Training Set ===========\n",
      "X_train: (700, 24)\n",
      "y_train: (700,)\n",
      "value counts:\n",
      "1    490\n",
      "2    210\n",
      "Name: 24, dtype: int64\n",
      "=========== Testing Set ===========\n",
      "X_test: (300, 24)\n",
      "y_test: (300,)\n",
      "value counts:\n",
      "1    210\n",
      "2     90\n",
      "Name: 24, dtype: int64\n",
      "=========================\n",
      "Grid searching best parameters for decision tree\n",
      "Accuracy for decision tree: 0.74\n",
      "F-score for decision tree: 0.8124999999999999\n",
      "==============================================================\n",
      "Random searching best parameters for random forest\n",
      "Accuracy for random forest: 0.7766666666666666\n",
      "Best F-score for random forest: 0.8533916849015317\n",
      "==============================================================\n",
      "Random searching best parameters for SVM\n",
      "Accuracy for svm: 0.7633333333333333\n",
      "Best F-score for svm: 0.8397291196388261\n",
      "==========================================\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "10/10 [==============================] - 0s 886us/step\n",
      "Accuracy for neural network: 0.7\n",
      "Best F-score for neural network: 0.8235294117647058\n",
      "==============================================================\n",
      "Current dataset: Australian\n",
      "=========== Training Set ===========\n",
      "X_train: (483, 14)\n",
      "y_train: (483,)\n",
      "value counts:\n",
      "0    268\n",
      "1    215\n",
      "Name: 14, dtype: int64\n",
      "=========== Testing Set ===========\n",
      "X_test: (207, 14)\n",
      "y_test: (207,)\n",
      "value counts:\n",
      "0    115\n",
      "1     92\n",
      "Name: 14, dtype: int64\n",
      "=========================\n",
      "Grid searching best parameters for decision tree\n",
      "Accuracy for decision tree: 0.821256038647343\n",
      "F-score for decision tree: 0.8229665071770336\n",
      "==============================================================\n",
      "Random searching best parameters for random forest\n",
      "Accuracy for random forest: 0.8599033816425121\n",
      "Best F-score for random forest: 0.8512820512820513\n",
      "==============================================================\n",
      "Random searching best parameters for SVM\n",
      "Accuracy for svm: 0.8357487922705314\n",
      "Best F-score for svm: 0.8365384615384616\n",
      "==========================================\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "7/7 [==============================] - 0s 831us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX_test: \u001b[39m\u001b[39m{\u001b[39;00mX_test\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39my_test: \u001b[39m\u001b[39m{\u001b[39;00my_test\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mvalue counts:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00my_test\u001b[39m.\u001b[39mvalue_counts()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m=========================\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m model_score \u001b[39m=\u001b[39m run_all_models(X_train, X_test, y_train, y_test)\n\u001b[0;32m     13\u001b[0m model_score[\u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [dataset_getter\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m4\u001b[39m\n\u001b[0;32m     14\u001b[0m stats_list\u001b[39m.\u001b[39mappend(pd\u001b[39m.\u001b[39mDataFrame(model_score))\n",
      "Cell \u001b[1;32mIn [18], line 5\u001b[0m, in \u001b[0;36mrun_all_models\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      3\u001b[0m acc_rf, f_rf, best_params_rf \u001b[39m=\u001b[39m RF(X_train, X_test, y_train, y_test)\n\u001b[0;32m      4\u001b[0m acc_svm, f_svm, best_params_svm \u001b[39m=\u001b[39m SVM(X_train, X_test, y_train, y_test)\n\u001b[1;32m----> 5\u001b[0m acc_nn, f_nn, best_params_nn \u001b[39m=\u001b[39m NN(X_train, X_test, y_train, y_test)\n\u001b[0;32m      6\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m      7\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m'\u001b[39m\u001b[39mdecision tree\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrandom forest\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msvm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mneural network\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      8\u001b[0m     \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m:[acc_dt, acc_rf, acc_svm, acc_nn],\n\u001b[0;32m      9\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mf1_score\u001b[39m\u001b[39m'\u001b[39m:[f_dt, f_rf, f_svm, f_nn],\n\u001b[0;32m     10\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodel_parameters\u001b[39m\u001b[39m'\u001b[39m:[best_params_dt, best_params_rf, best_params_svm, best_params_nn]\n\u001b[0;32m     11\u001b[0m     }\n",
      "Cell \u001b[1;32mIn [17], line 22\u001b[0m, in \u001b[0;36mNN\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     19\u001b[0m n \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_hyperparameters()[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mno_neurons_1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m l \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_hyperparameters()[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m \u001b[39mreturn\u001b[39;00m best_model(n,l, X_train, X_test, y_train, y_test)\n",
      "Cell \u001b[1;32mIn [16], line 25\u001b[0m, in \u001b[0;36mbest_model\u001b[1;34m(n, l, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     17\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train,\n\u001b[0;32m     18\u001b[0m          validation_data\u001b[39m=\u001b[39m(X_test, y_test),\n\u001b[0;32m     19\u001b[0m          batch_size \u001b[39m=\u001b[39m batch,\n\u001b[0;32m     20\u001b[0m          epochs \u001b[39m=\u001b[39m max_epochs,\n\u001b[0;32m     21\u001b[0m          verbose \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \n\u001b[0;32m     22\u001b[0m          callbacks \u001b[39m=\u001b[39m [early_stopping])\n\u001b[0;32m     24\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 25\u001b[0m acc \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39;49maccuracy_score(y_test, y_pred)\n\u001b[0;32m     26\u001b[0m f \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mf1_score(y_test, y_pred)\n\u001b[0;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy for neural network:\u001b[39m\u001b[39m\"\u001b[39m,acc)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\GitHub\\CZ4032-Project2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\GitHub\\CZ4032-Project2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "#German dataset\n",
    "dataset_funcs = [German, Australian, Crx, Horse, Vehicle, Pumpkin, Water, Banking]\n",
    "stats_list = []\n",
    "for dataset_getter in dataset_funcs:\n",
    "    print(f\"Current dataset: {dataset_getter.__name__}\")\n",
    "    X_train, X_test, y_train, y_test = dataset_getter()\n",
    "    print(\"=========== Training Set ===========\")\n",
    "    print(f\"X_train: {X_train.shape}\\ny_train: {y_train.shape}\\nvalue counts:\\n{y_train.value_counts()}\")\n",
    "    print(\"=========== Testing Set ===========\")\n",
    "    print(f\"X_test: {X_test.shape}\\ny_test: {y_test.shape}\\nvalue counts:\\n{y_test.value_counts()}\")\n",
    "    print(\"=========================\")\n",
    "    model_score = run_all_models(X_train, X_test, y_train, y_test)\n",
    "    model_score['dataset'] = [dataset_getter.__name__]*4\n",
    "    stats_list.append(pd.DataFrame(model_score))\n",
    "pd.concat(stats_list).to_csv(\"model_scores.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "53ab2871ffcc1d5758548d7aac039882a39be9d4e8a177725cd1279cfa69c6fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
