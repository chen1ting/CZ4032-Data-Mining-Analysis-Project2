{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from functools import cmp_to_key\n",
    "import sys\n",
    "\n",
    "INPUT = \"datasets\"\n",
    "OUTPUT = \"part1_results\"\n",
    "if not os.path.exists(OUTPUT):\n",
    "    os.makedirs(OUTPUT)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing method\n",
    "\n",
    "# Change categorical data to numerical data\n",
    "def cat_2_num(df:pd.DataFrame):\n",
    "    cat_columns = df.select_dtypes(['object']).columns\n",
    "    df[cat_columns] = df[cat_columns].astype('category')\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    return df\n",
    "\n",
    "# Use KMeans to get discretized data\n",
    "def get_discretization_data(df:pd.DataFrame):\n",
    "    for col_name in df.columns:\n",
    "        if(len(pd.unique(df[col_name])) <= 5):\n",
    "            return df\n",
    "        k = 5\n",
    "        k_model = KMeans(n_clusters=k)\n",
    "        k_model.fit(df[col_name].values.reshape(len(df[col_name]), 1))\n",
    "        c = pd.DataFrame(k_model.cluster_centers_, columns = list(\"a\")).sort_values(by = \"a\")\n",
    "        w = c.rolling(2).mean().iloc[1:]\n",
    "        w = np.asarray(w.values)\n",
    "        w = [i[0] for i in w]\n",
    "        w = [0] + w + [df[col_name].max()]\n",
    "        df[col_name] = pd.cut(df[col_name], w, labels = range(k))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCI datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#German dataset\n",
    "def German():\n",
    "    df = pd.read_table(os.path.join(INPUT,\"german.data-numeric\"),delim_whitespace = True, header = None)\n",
    "    df = get_discretization_data(df)\n",
    "    df[24] = df[24]-1    # change label from 1,2 to 0,1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Australian():\n",
    "    df = pd.read_table(os.path.join(INPUT,\"australian.dat\"),delim_whitespace = True, header = None)\n",
    "    df = get_discretization_data(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crx():\n",
    "    df = pd.read_csv(os.path.join(INPUT,\"crx.data\"), header = None)\n",
    "    # drop entries with ?\n",
    "    df = df.replace(\"?\", np.nan).dropna()\n",
    "    # convert category data to numerical data\n",
    "    df = cat_2_num(df)\n",
    "    df = get_discretization_data(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hepatitis():\n",
    "    df = pd.read_csv(os.path.join(INPUT,\"hepatitis.data\"), header = None)\n",
    "    df = cat_2_num(df)\n",
    "    df = get_discretization_data(df)\n",
    "    df[19] = df[19]-1 # change to 0 or 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ionosphere():\n",
    "    df = pd.read_csv(os.path.join(INPUT, \"ionosphere.data\"), header=None)\n",
    "    df = cat_2_num(df)\n",
    "    df = get_discretization_data(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Kaggle datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pumpkin():\n",
    "    df = pd.read_excel(os.path.join(\"datasets\",'Pumpkin_Seeds_Dataset.xlsx'), sheet_name='Pumpkin_Seeds_Dataset',engine='openpyxl')\n",
    "    df = cat_2_num(df)\n",
    "    df = get_discretization_data(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5644 samples, relatively large dataset\n",
    "def Mushroom():\n",
    "    df = pd.read_csv(os.path.join(INPUT,'mushrooms.csv'))\n",
    "    df = df.replace(\"?\", np.nan).dropna()\n",
    "    df = cat_2_num(df)\n",
    "    df = get_discretization_data(df)\n",
    "    order = list(df)\n",
    "    order = order[1:] + order[:1]\n",
    "    df = df[order]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Diabetes():\n",
    "    df = pd.read_csv(os.path.join(INPUT,'diabetes_data.csv'), sep=';')\n",
    "    df = cat_2_num(df)\n",
    "    df = get_discretization_data(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleItem:\n",
    "    \"\"\"\n",
    "    cond_set: a dict with following fashion:\n",
    "            {item name: value, item name: value, ...}\n",
    "        e.g.\n",
    "            {A: 1, B: 1} (A, B are name of columns, here called \"item\", and in our code should be numerical index\n",
    "                          but not string)\n",
    "    class_label: just to identify the class it belongs to.\n",
    "    dataset: a list returned by read method. (see read.py)\n",
    "    cond_sup_count, rule_sup_count, support and confidence are number.\n",
    "    \"\"\"\n",
    "    def __init__(self, cond_set, class_label, X_train, y_train):\n",
    "        self.cond_set = cond_set\n",
    "        self.class_label = class_label\n",
    "        self.cond_sup_count, self.rule_sup_count = self._get_sup_count(X_train, y_train)\n",
    "        self.support = self._get_support(len(X_train))\n",
    "        self.confidence = self._get_confidence()\n",
    "        self.is_pruned = False\n",
    "\n",
    "    # calculate condsupCount and rulesupCount\n",
    "    def _get_sup_count(self, X_train, y_train):\n",
    "        cond_sup_count = 0\n",
    "        rule_sup_count = 0\n",
    "        for i in range(len(X_train)):\n",
    "            is_contained = True\n",
    "            for index in self.cond_set:\n",
    "                if self.cond_set[index] != X_train[i][index]:\n",
    "                    is_contained = False\n",
    "                    break\n",
    "            if is_contained:\n",
    "                cond_sup_count += 1\n",
    "                if self.class_label == y_train[i]:\n",
    "                    rule_sup_count += 1\n",
    "        return cond_sup_count, rule_sup_count\n",
    "\n",
    "    # calculate support count\n",
    "    def _get_support(self, dataset_size):\n",
    "        return self.rule_sup_count / dataset_size\n",
    "\n",
    "    # calculate confidence\n",
    "    def _get_confidence(self):\n",
    "        if self.cond_sup_count != 0:\n",
    "            return self.rule_sup_count / self.cond_sup_count\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # print out the ruleitem\n",
    "    def print(self):\n",
    "        cond_set_output = ''\n",
    "        for item in self.cond_set:\n",
    "            cond_set_output += '(' + str(item) + ', ' + str(self.cond_set[item]) + '), '\n",
    "        cond_set_output = cond_set_output[:-2]\n",
    "        print('<({' + cond_set_output + '}, ' + str(self.cond_sup_count) + '), (' +\n",
    "              '(class, ' + str(self.class_label) + '), ' + str(self.rule_sup_count) + ')>' + \" cond_sup=\" + str(self.cond_sup_count) + \" rule_sup=\" + str(self.rule_sup_count))\n",
    "\n",
    "    # print out rule\n",
    "    def print_rule(self):\n",
    "        cond_set_output = ''\n",
    "        for item in self.cond_set:\n",
    "            cond_set_output += '(' + str(item) + ', ' + str(self.cond_set[item]) + '), '\n",
    "        cond_set_output = '{' + cond_set_output[:-2] + '}'\n",
    "        print(cond_set_output + ' -> (class, ' + str(self.class_label) + ')')\n",
    "    \n",
    "    # prune\n",
    "    def prune(self, rulelist):\n",
    "        for rule in rulelist:\n",
    "            if(self.confidence < rule.confidence):\n",
    "                self.is_pruned = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequentRuleitems:\n",
    "    \"\"\"\n",
    "    A set of frequent k-ruleitems, just using set.\n",
    "    \"\"\"\n",
    "    def __init__(self, class_label):\n",
    "        self.labels = class_label\n",
    "        self.frequent_ruleitems_set = {}\n",
    "        for label in class_label:\n",
    "            self.frequent_ruleitems_set[label] = set()\n",
    "\n",
    "    # get size of set\n",
    "    def get_size(self):\n",
    "        res = 0\n",
    "        for label in self.labels:\n",
    "            res += len(self.frequent_ruleitems_set[label])\n",
    "        return res\n",
    "\n",
    "    # add a new ruleitem into set\n",
    "    def add(self, rule_item):\n",
    "        is_existed = False\n",
    "        for item in self.frequent_ruleitems_set[rule_item.class_label]:\n",
    "            if item.cond_set == rule_item.cond_set:\n",
    "                is_existed = True\n",
    "                break\n",
    "        if not is_existed:\n",
    "            self.frequent_ruleitems_set[rule_item.class_label].add(rule_item)\n",
    "            \n",
    "    # print out all frequent ruleitems\n",
    "    def print(self):\n",
    "        for label in self.labels:\n",
    "            for item in self.frequent_ruleitems_set[label]:\n",
    "                item.print()\n",
    "\n",
    "\n",
    "class Car:\n",
    "    \"\"\"\n",
    "    Class Association Rules (Car). If some ruleitems has the same condset, the ruleitem with the highest confidence is\n",
    "    chosen as the Possible Rule (PR). If there're more than one ruleitem with the same highest confidence, we randomly\n",
    "    select one ruleitem.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.rules = set()\n",
    "        self.pruned_rules = set()\n",
    "\n",
    "    # print out all rules\n",
    "    def print_rule(self):\n",
    "        for item in self.rules:\n",
    "            item.print_rule()\n",
    "\n",
    "    # union new car into rules list\n",
    "    def append(self, car, minsup, minconf):\n",
    "        for item in car.rules:\n",
    "            self._add(item, minsup, minconf)\n",
    "\n",
    "    # add a new rule (frequent & accurate), save the ruleitem with the highest confidence when having the same condset\n",
    "    def _add(self, rule_item, minsup, minconf):\n",
    "        if rule_item.is_pruned == True:\n",
    "            return\n",
    "        if rule_item.support >= minsup and rule_item.confidence >= minconf:\n",
    "            if rule_item in self.rules:\n",
    "                return\n",
    "            for item in self.rules:\n",
    "                if item.cond_set == rule_item.cond_set and item.confidence < rule_item.confidence:\n",
    "                    self.rules.remove(item)\n",
    "                    self.rules.add(rule_item)\n",
    "                    return\n",
    "                elif item.cond_set == rule_item.cond_set and item.confidence >= rule_item.confidence:\n",
    "                    return\n",
    "            self.rules.add(rule_item)\n",
    "\n",
    "    # convert frequent ruleitems into car\n",
    "    def gen_rules(self, frequent_ruleitems, minsup, minconf):\n",
    "        for label in frequent_ruleitems.labels:\n",
    "            for item in frequent_ruleitems.frequent_ruleitems_set[label]:\n",
    "                self._add(item, minsup, minconf)\n",
    "\n",
    "# invoked by candidate_gen, join two items to generate candidate\n",
    "def join(item1, item2, X_train, y_train, minsup):\n",
    "    category1 = list(item1.cond_set.keys())\n",
    "    category2 = list(item2.cond_set.keys())\n",
    "    category1.sort()\n",
    "    category2.sort()\n",
    "    for i in range(len(category1) - 1):\n",
    "        if category1[i] != category2[i]:\n",
    "            return None\n",
    "        if item1.cond_set[category1[i]] != item2.cond_set[category1[i]]:\n",
    "            return None\n",
    "    i = len(category1) - 1\n",
    "    if category1[i] == category2[i]:\n",
    "        return None\n",
    "    new_cond_set = item1.cond_set.copy()\n",
    "    new_cond_set[category2[i]] = item2.cond_set[category2[i]]\n",
    "    new_ruleitem = RuleItem(new_cond_set, item1.class_label, X_train, y_train)\n",
    "    if new_ruleitem.support < minsup:\n",
    "        return None\n",
    "    new_ruleitem.prune([item1, item2])\n",
    "    return new_ruleitem\n",
    "\n",
    "\n",
    "\n",
    "# similar to Apriori-gen in algorithm Apriori\n",
    "def candidate_gen(frequent_ruleitems, X_train, y_train, minsup):\n",
    "    returned_frequent_ruleitems = FrequentRuleitems(frequent_ruleitems.labels)\n",
    "    for label in frequent_ruleitems.labels:\n",
    "        for item1 in frequent_ruleitems.frequent_ruleitems_set[label]:\n",
    "            for item2 in frequent_ruleitems.frequent_ruleitems_set[label]:\n",
    "                new_ruleitem = join(item1, item2, X_train, y_train, minsup)\n",
    "                if new_ruleitem:\n",
    "                    returned_frequent_ruleitems.add(new_ruleitem)\n",
    "                    if returned_frequent_ruleitems.get_size() >= 2000:      # not allow to store more than 2000 ruleitems\n",
    "                        return returned_frequent_ruleitems\n",
    "    return returned_frequent_ruleitems\n",
    "\n",
    "\n",
    "# main method, implementation of CBA-RG algorithm\n",
    "def rule_generator(X_train, y_train, minsup, minconf):\n",
    "\n",
    "    # get large 1-ruleitems and generate rules\n",
    "    class_label = set(y_train)\n",
    "    frequent_ruleitems = FrequentRuleitems(class_label)\n",
    "    car = Car()\n",
    "    for column in range(0, len(X_train[0])):\n",
    "        distinct_value = set([x[column] for x in X_train])\n",
    "        for value in distinct_value:\n",
    "            cond_set = {column: value}\n",
    "            for classes in class_label:\n",
    "                rule_item = RuleItem(cond_set, classes, X_train, y_train)\n",
    "                if rule_item.support >= minsup:\n",
    "                    frequent_ruleitems.add(rule_item)\n",
    "    car.gen_rules(frequent_ruleitems, minsup, minconf)\n",
    "    cars = car\n",
    "\n",
    "    current_cars_number = len(cars.rules)\n",
    "    while frequent_ruleitems.get_size() > 0 and current_cars_number <= 20000:\n",
    "        candidate = candidate_gen(frequent_ruleitems, X_train, y_train, minsup)\n",
    "        frequent_ruleitems = FrequentRuleitems(class_label)\n",
    "        car = Car()\n",
    "        for label in candidate.labels:\n",
    "            for item in candidate.frequent_ruleitems_set[label]:\n",
    "                if item.support >= minsup:\n",
    "                    frequent_ruleitems.add(item)\n",
    "        car.gen_rules(frequent_ruleitems, minsup, minconf)\n",
    "        cars.append(car, minsup, minconf)\n",
    "        current_cars_number = len(cars.rules)\n",
    "\n",
    "    return cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_satisfy(X_train, y_train, rule):\n",
    "    for item in rule.cond_set:\n",
    "        if X_train[item] != rule.cond_set[item]:\n",
    "            return None\n",
    "    if y_train == rule.class_label:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "    \"\"\"\n",
    "    This class is our classifier. The rule_list and default_class are useful for outer code.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.rule_list = list()\n",
    "        self.default_class = None\n",
    "        self._error_list = list()\n",
    "        self._default_class_list = list()\n",
    "\n",
    "    # insert a rule into rule_list, then choose a default class, and calculate the errors (see line 8, 10 & 11)\n",
    "    def insert(self, rule, X_train, y_train):\n",
    "        self.rule_list.append(rule)             # insert r at the end of C\n",
    "        self._select_default_class(y_train)     # select a default class for the current C\n",
    "        self._compute_error(X_train, y_train)            # compute the total number of errors of C\n",
    "\n",
    "    # select the majority class in the remaining data\n",
    "    def _select_default_class(self, y_train):\n",
    "        class_column = y_train\n",
    "        class_label = set(class_column)\n",
    "        max = 0\n",
    "        current_default_class = None\n",
    "        for label in class_label:\n",
    "            if class_column.count(label) >= max:\n",
    "                max = class_column.count(label)\n",
    "                current_default_class = label\n",
    "        self._default_class_list.append(current_default_class)\n",
    "\n",
    "    # compute the sum of errors\n",
    "    def _compute_error(self, X_train, y_train):\n",
    "        if len(X_train) <= 0:\n",
    "            self._error_list.append(sys.maxsize)\n",
    "            return\n",
    "\n",
    "        error_number = 0\n",
    "\n",
    "        # the number of errors that have been made by all the selected rules in C\n",
    "        for i in range(len(X_train)):\n",
    "            is_cover = False\n",
    "            for rule in self.rule_list:\n",
    "                if is_satisfy(X_train[i], y_train[i], rule):\n",
    "                    is_cover = True\n",
    "                    break\n",
    "            if not is_cover:\n",
    "                error_number += 1\n",
    "\n",
    "        # the number of errors to be made by the default class in the training set\n",
    "        class_column = y_train\n",
    "        error_number += len(class_column) - class_column.count(self._default_class_list[-1])\n",
    "        self._error_list.append(error_number)\n",
    "\n",
    "    # see line 14 and 15, to get the final classifier\n",
    "    def discard(self):\n",
    "        # find the first rule p in C with the lowest total number of errors and drop all the rules after p in C\n",
    "        index = self._error_list.index(min(self._error_list))\n",
    "        self.rule_list = self.rule_list[:(index+1)]\n",
    "        self._error_list = None\n",
    "\n",
    "        # assign the default class associated with p to default_class\n",
    "        self.default_class = self._default_class_list[index]\n",
    "        self._default_class_list = None\n",
    "\n",
    "    # just print out all selected rules and default class in our classifier\n",
    "    def print(self):\n",
    "        for rule in self.rule_list:\n",
    "            rule.print()\n",
    "        print(\"default_class:\", self.default_class)\n",
    "\n",
    "\n",
    "# sort the set of generated rules car according to the relation \">\", return the sorted rule list\n",
    "def sort(car):\n",
    "    def cmp_method(a, b):\n",
    "        if a.confidence < b.confidence:     # 1. the confidence of ri > rj\n",
    "            return 1\n",
    "        elif a.confidence == b.confidence:\n",
    "            if a.support < b.support:       # 2. their confidences are the same, but support of ri > rj\n",
    "                return 1\n",
    "            elif a.support == b.support:\n",
    "                if len(a.cond_set) < len(b.cond_set):   # 3. both confidence & support are the same, ri earlier than rj\n",
    "                    return -1\n",
    "                elif len(a.cond_set) == len(b.cond_set):\n",
    "                    return 0\n",
    "                else:\n",
    "                    return 1\n",
    "            else:\n",
    "                return -1\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    rule_list = list(car.rules)\n",
    "    rule_list.sort(key=cmp_to_key(cmp_method))\n",
    "    return rule_list\n",
    "\n",
    "\n",
    "# main method of CBA-CB: M1\n",
    "def classifier_builder_m1(cars, X_train, y_train):\n",
    "    classifier = Classifier()\n",
    "    cars_list = sort(cars)\n",
    "    for rule in cars_list:\n",
    "        temp = []\n",
    "        mark = False\n",
    "        for i in range(len(X_train)):\n",
    "            is_satisfy_value = is_satisfy(X_train[i], y_train[i], rule)\n",
    "            if is_satisfy_value is not None:\n",
    "                temp.append(i)\n",
    "                if is_satisfy_value:\n",
    "                    mark = True\n",
    "        if mark:\n",
    "            temp.sort(reverse=True)\n",
    "            for i in temp:\n",
    "                X_train.pop(i)\n",
    "                y_train.pop(i)\n",
    "            classifier.insert(rule, X_train, y_train)\n",
    "    classifier.discard()\n",
    "    return classifier\n",
    "\n",
    "# calculate the error rate of the classifier on the dataset\n",
    "def predict(classifier, X_test):\n",
    "    pred = []\n",
    "    for case in X_test:\n",
    "        is_satisfy_value = False\n",
    "        for rule in classifier.rule_list:\n",
    "            match = True\n",
    "            for item in rule.cond_set:\n",
    "                if case[item] != rule.cond_set[item]:\n",
    "                    match = False\n",
    "                    break\n",
    "            if match == True:\n",
    "                pred.append(rule.class_label)\n",
    "                is_satisfy_value = True\n",
    "                break\n",
    "        if is_satisfy_value == False:\n",
    "            pred.append(classifier.default_class)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold cross-validations on CBA (M1)\n",
    "def cross_validate_m1(dataset, minsup=0.01, minconf=0.8, quiet=False):\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    cba_rg_total_runtime = 0\n",
    "    cba_cb_total_runtime = 0\n",
    "    total_car_number = 0\n",
    "    total_classifier_rule_num = 0\n",
    "    accs = []\n",
    "    fs = []\n",
    "    k = 0\n",
    "\n",
    "    X = [x[:-1] for x in dataset]\n",
    "    y = [x[-1] for x in dataset]\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        if not quiet:\n",
    "            print(\"\\nRound %d:\" % k)\n",
    "\n",
    "        X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "        y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "\n",
    "        start_time = time.time()\n",
    "        cars = rule_generator(X_train, y_train, minsup, minconf)\n",
    "        end_time = time.time()\n",
    "        cba_rg_runtime = end_time - start_time\n",
    "        cba_rg_total_runtime += cba_rg_runtime\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "        classifier_m1 = classifier_builder_m1(cars, X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        cba_cb_runtime = end_time - start_time\n",
    "        cba_cb_total_runtime += cba_cb_runtime\n",
    "\n",
    "        pred = predict(classifier_m1, X_test)\n",
    "        \n",
    "        acc = metrics.accuracy_score(y_test, pred)\n",
    "        f = metrics.f1_score(y_test, pred, pos_label = 1)\n",
    "        # ctx = metrics.confusion_matrix(y_test, pred)\n",
    "        # sns.heatmap(ctx, cmap='Oranges', annot=True, fmt='g')\n",
    "        # plt.show()\n",
    "        accs.append(acc)\n",
    "        fs.append(f)\n",
    "\n",
    "        total_car_number += len(cars.rules)\n",
    "        total_classifier_rule_num += len(classifier_m1.rule_list)\n",
    "\n",
    "        if not quiet:\n",
    "            print(f\"\\nCBA's accuracy with pruning: {(acc):.2}\")\n",
    "            print(f\"CBA's f1-score with pruning: {(f):.2}\")\n",
    "            print(\"No. of CARs with pruning: %d\" % len(cars.rules))\n",
    "            print(\"CBA-RG's run time with pruning: %.2lf s\" % cba_rg_runtime)\n",
    "            print(\"CBA-CB M1's run time with pruning: %.2lf s\" % cba_cb_runtime)\n",
    "            print(\"No. of rules in classifier of CBA-CB M1 with pruning: %d\" % len(classifier_m1.rule_list))\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    if not quiet:    \n",
    "        print(f\"\\nAverage CBA's accuracy with pruning: {(sum(accs)/len(accs)):.2}\")\n",
    "        print(f\"Average CBA's f1-score with pruning: {(sum(fs)/len(accs)):.2}\")\n",
    "        print(f\"Average No. of CARs with pruning: {int(total_car_number / 10)}\")\n",
    "        print(f\"Average CBA-RG's run time with pruning: {(cba_rg_total_runtime / 10):.3f} s\")\n",
    "        print(f\"Average CBA-CB M1's run time with pruning: {(cba_cb_total_runtime / 10):.3f} s\")\n",
    "        print(f\"Average No. of rules in classifier of CBA-CB M1 with pruning: {int(total_classifier_rule_num / 10)}\")\n",
    "    return sum(accs)/len(accs), sum(fs)/len(fs), int(total_car_number / 10), (cba_rg_total_runtime / 10), (cba_cb_total_runtime / 10), int(total_classifier_rule_num / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying German dataset\n",
      "\n",
      "Round 0:\n",
      "\n",
      "CBA's accuracy with pruning: 0.74\n",
      "CBA's f1-score with pruning: 0.35\n",
      "No. of CARs with pruning: 1656\n",
      "CBA-RG's run time with pruning: 21.53 s\n",
      "CBA-CB M1's run time with pruning: 0.93 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 154\n",
      "\n",
      "Round 1:\n",
      "\n",
      "CBA's accuracy with pruning: 0.73\n",
      "CBA's f1-score with pruning: 0.34\n",
      "No. of CARs with pruning: 1234\n",
      "CBA-RG's run time with pruning: 31.37 s\n",
      "CBA-CB M1's run time with pruning: 0.98 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 157\n",
      "\n",
      "Round 2:\n",
      "\n",
      "CBA's accuracy with pruning: 0.76\n",
      "CBA's f1-score with pruning: 0.2\n",
      "No. of CARs with pruning: 1341\n",
      "CBA-RG's run time with pruning: 30.94 s\n",
      "CBA-CB M1's run time with pruning: 0.92 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 150\n",
      "\n",
      "Round 3:\n",
      "\n",
      "CBA's accuracy with pruning: 0.7\n",
      "CBA's f1-score with pruning: 0.32\n",
      "No. of CARs with pruning: 7098\n",
      "CBA-RG's run time with pruning: 36.86 s\n",
      "CBA-CB M1's run time with pruning: 1.73 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 166\n",
      "\n",
      "Round 4:\n",
      "\n",
      "CBA's accuracy with pruning: 0.73\n",
      "CBA's f1-score with pruning: 0.31\n",
      "No. of CARs with pruning: 3943\n",
      "CBA-RG's run time with pruning: 38.70 s\n",
      "CBA-CB M1's run time with pruning: 0.90 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 147\n",
      "\n",
      "Round 5:\n",
      "\n",
      "CBA's accuracy with pruning: 0.78\n",
      "CBA's f1-score with pruning: 0.27\n",
      "No. of CARs with pruning: 1692\n",
      "CBA-RG's run time with pruning: 38.58 s\n",
      "CBA-CB M1's run time with pruning: 1.12 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 152\n",
      "\n",
      "Round 6:\n",
      "\n",
      "CBA's accuracy with pruning: 0.7\n",
      "CBA's f1-score with pruning: 0.12\n",
      "No. of CARs with pruning: 5547\n",
      "CBA-RG's run time with pruning: 39.80 s\n",
      "CBA-CB M1's run time with pruning: 1.71 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 192\n",
      "\n",
      "Round 7:\n",
      "\n",
      "CBA's accuracy with pruning: 0.73\n",
      "CBA's f1-score with pruning: 0.34\n",
      "No. of CARs with pruning: 1979\n",
      "CBA-RG's run time with pruning: 40.44 s\n",
      "CBA-CB M1's run time with pruning: 1.27 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 172\n",
      "\n",
      "Round 8:\n",
      "\n",
      "CBA's accuracy with pruning: 0.71\n",
      "CBA's f1-score with pruning: 0.26\n",
      "No. of CARs with pruning: 8489\n",
      "CBA-RG's run time with pruning: 43.18 s\n",
      "CBA-CB M1's run time with pruning: 2.24 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 181\n",
      "\n",
      "Round 9:\n",
      "\n",
      "CBA's accuracy with pruning: 0.6\n",
      "CBA's f1-score with pruning: 0.13\n",
      "No. of CARs with pruning: 5399\n",
      "CBA-RG's run time with pruning: 28.08 s\n",
      "CBA-CB M1's run time with pruning: 1.32 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 165\n",
      "\n",
      "Average CBA's accuracy with pruning: 0.72\n",
      "Average CBA's f1-score with pruning: 0.26\n",
      "Average No. of CARs with pruning: 3837\n",
      "Average CBA-RG's run time with pruning: 34.948 s\n",
      "Average CBA-CB M1's run time with pruning: 1.312 s\n",
      "Average No. of rules in classifier of CBA-CB M1 with pruning: 163\n",
      "Classifying Australian dataset\n",
      "\n",
      "Round 0:\n",
      "\n",
      "CBA's accuracy with pruning: 0.86\n",
      "CBA's f1-score with pruning: 0.81\n",
      "No. of CARs with pruning: 3751\n",
      "CBA-RG's run time with pruning: 20.45 s\n",
      "CBA-CB M1's run time with pruning: 0.50 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 117\n",
      "\n",
      "Round 1:\n",
      "\n",
      "CBA's accuracy with pruning: 0.9\n",
      "CBA's f1-score with pruning: 0.84\n",
      "No. of CARs with pruning: 3428\n",
      "CBA-RG's run time with pruning: 20.56 s\n",
      "CBA-CB M1's run time with pruning: 0.57 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 111\n",
      "\n",
      "Round 2:\n",
      "\n",
      "CBA's accuracy with pruning: 0.77\n",
      "CBA's f1-score with pruning: 0.73\n",
      "No. of CARs with pruning: 3463\n",
      "CBA-RG's run time with pruning: 16.25 s\n",
      "CBA-CB M1's run time with pruning: 0.37 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 113\n",
      "\n",
      "Round 3:\n",
      "\n",
      "CBA's accuracy with pruning: 0.91\n",
      "CBA's f1-score with pruning: 0.9\n",
      "No. of CARs with pruning: 3224\n",
      "CBA-RG's run time with pruning: 16.66 s\n",
      "CBA-CB M1's run time with pruning: 0.63 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 116\n",
      "\n",
      "Round 4:\n",
      "\n",
      "CBA's accuracy with pruning: 0.84\n",
      "CBA's f1-score with pruning: 0.81\n",
      "No. of CARs with pruning: 3982\n",
      "CBA-RG's run time with pruning: 19.98 s\n",
      "CBA-CB M1's run time with pruning: 0.58 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 118\n",
      "\n",
      "Round 5:\n",
      "\n",
      "CBA's accuracy with pruning: 0.84\n",
      "CBA's f1-score with pruning: 0.78\n",
      "No. of CARs with pruning: 3215\n",
      "CBA-RG's run time with pruning: 17.80 s\n",
      "CBA-CB M1's run time with pruning: 0.59 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 116\n",
      "\n",
      "Round 6:\n",
      "\n",
      "CBA's accuracy with pruning: 0.75\n",
      "CBA's f1-score with pruning: 0.75\n",
      "No. of CARs with pruning: 3586\n",
      "CBA-RG's run time with pruning: 17.62 s\n",
      "CBA-CB M1's run time with pruning: 0.55 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 113\n",
      "\n",
      "Round 7:\n",
      "\n",
      "CBA's accuracy with pruning: 0.83\n",
      "CBA's f1-score with pruning: 0.82\n",
      "No. of CARs with pruning: 3822\n",
      "CBA-RG's run time with pruning: 19.46 s\n",
      "CBA-CB M1's run time with pruning: 0.46 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 116\n",
      "\n",
      "Round 8:\n",
      "\n",
      "CBA's accuracy with pruning: 0.81\n",
      "CBA's f1-score with pruning: 0.78\n",
      "No. of CARs with pruning: 3562\n",
      "CBA-RG's run time with pruning: 18.13 s\n",
      "CBA-CB M1's run time with pruning: 0.50 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 118\n",
      "\n",
      "Round 9:\n",
      "\n",
      "CBA's accuracy with pruning: 0.8\n",
      "CBA's f1-score with pruning: 0.79\n",
      "No. of CARs with pruning: 3659\n",
      "CBA-RG's run time with pruning: 18.58 s\n",
      "CBA-CB M1's run time with pruning: 0.55 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 113\n",
      "\n",
      "Average CBA's accuracy with pruning: 0.83\n",
      "Average CBA's f1-score with pruning: 0.8\n",
      "Average No. of CARs with pruning: 3569\n",
      "Average CBA-RG's run time with pruning: 18.548 s\n",
      "Average CBA-CB M1's run time with pruning: 0.530 s\n",
      "Average No. of rules in classifier of CBA-CB M1 with pruning: 115\n",
      "Classifying Crx dataset\n",
      "\n",
      "Round 0:\n",
      "\n",
      "CBA's accuracy with pruning: 0.83\n",
      "CBA's f1-score with pruning: 0.84\n",
      "No. of CARs with pruning: 3564\n",
      "CBA-RG's run time with pruning: 18.72 s\n",
      "CBA-CB M1's run time with pruning: 0.35 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 131\n",
      "\n",
      "Round 1:\n",
      "\n",
      "CBA's accuracy with pruning: 0.91\n",
      "CBA's f1-score with pruning: 0.92\n",
      "No. of CARs with pruning: 3378\n",
      "CBA-RG's run time with pruning: 20.74 s\n",
      "CBA-CB M1's run time with pruning: 0.31 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 131\n",
      "\n",
      "Round 2:\n",
      "\n",
      "CBA's accuracy with pruning: 0.88\n",
      "CBA's f1-score with pruning: 0.89\n",
      "No. of CARs with pruning: 3056\n",
      "CBA-RG's run time with pruning: 16.92 s\n",
      "CBA-CB M1's run time with pruning: 0.30 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 129\n",
      "\n",
      "Round 3:\n",
      "\n",
      "CBA's accuracy with pruning: 0.92\n",
      "CBA's f1-score with pruning: 0.94\n",
      "No. of CARs with pruning: 2790\n",
      "CBA-RG's run time with pruning: 15.97 s\n",
      "CBA-CB M1's run time with pruning: 0.28 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 128\n",
      "\n",
      "Round 4:\n",
      "\n",
      "CBA's accuracy with pruning: 0.85\n",
      "CBA's f1-score with pruning: 0.85\n",
      "No. of CARs with pruning: 3002\n",
      "CBA-RG's run time with pruning: 17.59 s\n",
      "CBA-CB M1's run time with pruning: 0.29 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 127\n",
      "\n",
      "Round 5:\n",
      "\n",
      "CBA's accuracy with pruning: 0.94\n",
      "CBA's f1-score with pruning: 0.95\n",
      "No. of CARs with pruning: 3197\n",
      "CBA-RG's run time with pruning: 19.20 s\n",
      "CBA-CB M1's run time with pruning: 0.60 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 129\n",
      "\n",
      "Round 6:\n",
      "\n",
      "CBA's accuracy with pruning: 0.77\n",
      "CBA's f1-score with pruning: 0.79\n",
      "No. of CARs with pruning: 3361\n",
      "CBA-RG's run time with pruning: 18.61 s\n",
      "CBA-CB M1's run time with pruning: 0.27 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 124\n",
      "\n",
      "Round 7:\n",
      "\n",
      "CBA's accuracy with pruning: 0.86\n",
      "CBA's f1-score with pruning: 0.88\n",
      "No. of CARs with pruning: 3209\n",
      "CBA-RG's run time with pruning: 18.62 s\n",
      "CBA-CB M1's run time with pruning: 0.30 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 121\n",
      "\n",
      "Round 8:\n",
      "\n",
      "CBA's accuracy with pruning: 0.85\n",
      "CBA's f1-score with pruning: 0.84\n",
      "No. of CARs with pruning: 3089\n",
      "CBA-RG's run time with pruning: 19.28 s\n",
      "CBA-CB M1's run time with pruning: 0.32 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 130\n",
      "\n",
      "Round 9:\n",
      "\n",
      "CBA's accuracy with pruning: 0.83\n",
      "CBA's f1-score with pruning: 0.83\n",
      "No. of CARs with pruning: 3048\n",
      "CBA-RG's run time with pruning: 18.45 s\n",
      "CBA-CB M1's run time with pruning: 0.29 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 119\n",
      "\n",
      "Average CBA's accuracy with pruning: 0.86\n",
      "Average CBA's f1-score with pruning: 0.87\n",
      "Average No. of CARs with pruning: 3169\n",
      "Average CBA-RG's run time with pruning: 18.409 s\n",
      "Average CBA-CB M1's run time with pruning: 0.332 s\n",
      "Average No. of rules in classifier of CBA-CB M1 with pruning: 126\n",
      "Classifying Hepatitis dataset\n",
      "\n",
      "Round 0:\n",
      "\n",
      "CBA's accuracy with pruning: 0.81\n",
      "CBA's f1-score with pruning: 0.82\n",
      "No. of CARs with pruning: 10216\n",
      "CBA-RG's run time with pruning: 45.36 s\n",
      "CBA-CB M1's run time with pruning: 0.08 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 66\n",
      "\n",
      "Round 1:\n",
      "\n",
      "CBA's accuracy with pruning: 0.5\n",
      "CBA's f1-score with pruning: 0.2\n",
      "No. of CARs with pruning: 8408\n",
      "CBA-RG's run time with pruning: 26.55 s\n",
      "CBA-CB M1's run time with pruning: 0.08 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 55\n",
      "\n",
      "Round 2:\n",
      "\n",
      "CBA's accuracy with pruning: 0.81\n",
      "CBA's f1-score with pruning: 0.82\n",
      "No. of CARs with pruning: 8926\n",
      "CBA-RG's run time with pruning: 30.59 s\n",
      "CBA-CB M1's run time with pruning: 0.09 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 66\n",
      "\n",
      "Round 3:\n",
      "\n",
      "CBA's accuracy with pruning: 0.88\n",
      "CBA's f1-score with pruning: 0.89\n",
      "No. of CARs with pruning: 9315\n",
      "CBA-RG's run time with pruning: 33.38 s\n",
      "CBA-CB M1's run time with pruning: 0.12 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 56\n",
      "\n",
      "Round 4:\n",
      "\n",
      "CBA's accuracy with pruning: 0.88\n",
      "CBA's f1-score with pruning: 0.8\n",
      "No. of CARs with pruning: 8640\n",
      "CBA-RG's run time with pruning: 33.94 s\n",
      "CBA-CB M1's run time with pruning: 0.08 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 67\n",
      "\n",
      "Round 5:\n",
      "\n",
      "CBA's accuracy with pruning: 0.53\n",
      "CBA's f1-score with pruning: 0.36\n",
      "No. of CARs with pruning: 8642\n",
      "CBA-RG's run time with pruning: 29.79 s\n",
      "CBA-CB M1's run time with pruning: 0.07 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 69\n",
      "\n",
      "Round 6:\n",
      "\n",
      "CBA's accuracy with pruning: 0.67\n",
      "CBA's f1-score with pruning: 0.62\n",
      "No. of CARs with pruning: 6914\n",
      "CBA-RG's run time with pruning: 24.99 s\n",
      "CBA-CB M1's run time with pruning: 0.12 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 67\n",
      "\n",
      "Round 7:\n",
      "\n",
      "CBA's accuracy with pruning: 0.67\n",
      "CBA's f1-score with pruning: 0.62\n",
      "No. of CARs with pruning: 9145\n",
      "CBA-RG's run time with pruning: 30.84 s\n",
      "CBA-CB M1's run time with pruning: 0.06 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 63\n",
      "\n",
      "Round 8:\n",
      "\n",
      "CBA's accuracy with pruning: 0.67\n",
      "CBA's f1-score with pruning: 0.74\n",
      "No. of CARs with pruning: 10845\n",
      "CBA-RG's run time with pruning: 37.62 s\n",
      "CBA-CB M1's run time with pruning: 0.15 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 67\n",
      "\n",
      "Round 9:\n",
      "\n",
      "CBA's accuracy with pruning: 0.53\n",
      "CBA's f1-score with pruning: 0.59\n",
      "No. of CARs with pruning: 10400\n",
      "CBA-RG's run time with pruning: 40.11 s\n",
      "CBA-CB M1's run time with pruning: 0.08 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 63\n",
      "\n",
      "Average CBA's accuracy with pruning: 0.69\n",
      "Average CBA's f1-score with pruning: 0.65\n",
      "Average No. of CARs with pruning: 9145\n",
      "Average CBA-RG's run time with pruning: 33.318 s\n",
      "Average CBA-CB M1's run time with pruning: 0.093 s\n",
      "Average No. of rules in classifier of CBA-CB M1 with pruning: 63\n",
      "Classifying Ionosphere dataset\n",
      "\n",
      "Round 0:\n",
      "\n",
      "CBA's accuracy with pruning: 0.89\n",
      "CBA's f1-score with pruning: 0.91\n",
      "No. of CARs with pruning: 14219\n",
      "CBA-RG's run time with pruning: 37.88 s\n",
      "CBA-CB M1's run time with pruning: 0.84 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 32\n",
      "\n",
      "Round 1:\n",
      "\n",
      "CBA's accuracy with pruning: 0.8\n",
      "CBA's f1-score with pruning: 0.83\n",
      "No. of CARs with pruning: 18960\n",
      "CBA-RG's run time with pruning: 55.06 s\n",
      "CBA-CB M1's run time with pruning: 0.92 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 29\n",
      "\n",
      "Round 2:\n",
      "\n",
      "CBA's accuracy with pruning: 0.77\n",
      "CBA's f1-score with pruning: 0.76\n",
      "No. of CARs with pruning: 21542\n",
      "CBA-RG's run time with pruning: 57.09 s\n",
      "CBA-CB M1's run time with pruning: 1.17 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 30\n",
      "\n",
      "Round 3:\n",
      "\n",
      "CBA's accuracy with pruning: 0.86\n",
      "CBA's f1-score with pruning: 0.9\n",
      "No. of CARs with pruning: 8773\n",
      "CBA-RG's run time with pruning: 18.90 s\n",
      "CBA-CB M1's run time with pruning: 0.54 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 32\n",
      "\n",
      "Round 4:\n",
      "\n",
      "CBA's accuracy with pruning: 0.71\n",
      "CBA's f1-score with pruning: 0.81\n",
      "No. of CARs with pruning: 20289\n",
      "CBA-RG's run time with pruning: 62.31 s\n",
      "CBA-CB M1's run time with pruning: 0.96 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 30\n",
      "\n",
      "Round 5:\n",
      "\n",
      "CBA's accuracy with pruning: 0.89\n",
      "CBA's f1-score with pruning: 0.9\n",
      "No. of CARs with pruning: 21533\n",
      "CBA-RG's run time with pruning: 55.47 s\n",
      "CBA-CB M1's run time with pruning: 1.02 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 35\n",
      "\n",
      "Round 6:\n",
      "\n",
      "CBA's accuracy with pruning: 0.89\n",
      "CBA's f1-score with pruning: 0.92\n",
      "No. of CARs with pruning: 20962\n",
      "CBA-RG's run time with pruning: 62.70 s\n",
      "CBA-CB M1's run time with pruning: 0.96 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 30\n",
      "\n",
      "Round 7:\n",
      "\n",
      "CBA's accuracy with pruning: 0.89\n",
      "CBA's f1-score with pruning: 0.91\n",
      "No. of CARs with pruning: 14327\n",
      "CBA-RG's run time with pruning: 34.45 s\n",
      "CBA-CB M1's run time with pruning: 0.75 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 32\n",
      "\n",
      "Round 8:\n",
      "\n",
      "CBA's accuracy with pruning: 0.86\n",
      "CBA's f1-score with pruning: 0.88\n",
      "No. of CARs with pruning: 21534\n",
      "CBA-RG's run time with pruning: 60.33 s\n",
      "CBA-CB M1's run time with pruning: 1.00 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 27\n",
      "\n",
      "Round 9:\n",
      "\n",
      "CBA's accuracy with pruning: 0.86\n",
      "CBA's f1-score with pruning: 0.88\n",
      "No. of CARs with pruning: 12828\n",
      "CBA-RG's run time with pruning: 35.22 s\n",
      "CBA-CB M1's run time with pruning: 0.63 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 31\n",
      "\n",
      "Average CBA's accuracy with pruning: 0.84\n",
      "Average CBA's f1-score with pruning: 0.87\n",
      "Average No. of CARs with pruning: 17496\n",
      "Average CBA-RG's run time with pruning: 47.940 s\n",
      "Average CBA-CB M1's run time with pruning: 0.878 s\n",
      "Average No. of rules in classifier of CBA-CB M1 with pruning: 30\n",
      "Classifying Pumpkin dataset\n",
      "\n",
      "Round 0:\n",
      "\n",
      "CBA's accuracy with pruning: 0.89\n",
      "CBA's f1-score with pruning: 0.88\n",
      "No. of CARs with pruning: 2785\n",
      "CBA-RG's run time with pruning: 18.98 s\n",
      "CBA-CB M1's run time with pruning: 3.90 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 232\n",
      "\n",
      "Round 1:\n",
      "\n",
      "CBA's accuracy with pruning: 0.88\n",
      "CBA's f1-score with pruning: 0.88\n",
      "No. of CARs with pruning: 3226\n",
      "CBA-RG's run time with pruning: 27.72 s\n",
      "CBA-CB M1's run time with pruning: 3.67 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 250\n",
      "\n",
      "Round 2:\n",
      "\n",
      "CBA's accuracy with pruning: 0.86\n",
      "CBA's f1-score with pruning: 0.84\n",
      "No. of CARs with pruning: 3424\n",
      "CBA-RG's run time with pruning: 27.41 s\n",
      "CBA-CB M1's run time with pruning: 3.59 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 243\n",
      "\n",
      "Round 3:\n",
      "\n",
      "CBA's accuracy with pruning: 0.88\n",
      "CBA's f1-score with pruning: 0.88\n",
      "No. of CARs with pruning: 2961\n",
      "CBA-RG's run time with pruning: 21.01 s\n",
      "CBA-CB M1's run time with pruning: 3.61 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 239\n",
      "\n",
      "Round 4:\n",
      "\n",
      "CBA's accuracy with pruning: 0.89\n",
      "CBA's f1-score with pruning: 0.89\n",
      "No. of CARs with pruning: 3672\n",
      "CBA-RG's run time with pruning: 29.80 s\n",
      "CBA-CB M1's run time with pruning: 4.37 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 244\n",
      "\n",
      "Round 5:\n",
      "\n",
      "CBA's accuracy with pruning: 0.88\n",
      "CBA's f1-score with pruning: 0.87\n",
      "No. of CARs with pruning: 3038\n",
      "CBA-RG's run time with pruning: 30.92 s\n",
      "CBA-CB M1's run time with pruning: 4.05 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 241\n",
      "\n",
      "Round 6:\n",
      "\n",
      "CBA's accuracy with pruning: 0.9\n",
      "CBA's f1-score with pruning: 0.89\n",
      "No. of CARs with pruning: 3572\n",
      "CBA-RG's run time with pruning: 25.68 s\n",
      "CBA-CB M1's run time with pruning: 4.50 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 251\n",
      "\n",
      "Round 7:\n",
      "\n",
      "CBA's accuracy with pruning: 0.88\n",
      "CBA's f1-score with pruning: 0.86\n",
      "No. of CARs with pruning: 4028\n",
      "CBA-RG's run time with pruning: 30.62 s\n",
      "CBA-CB M1's run time with pruning: 3.55 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 237\n",
      "\n",
      "Round 8:\n",
      "\n",
      "CBA's accuracy with pruning: 0.85\n",
      "CBA's f1-score with pruning: 0.85\n",
      "No. of CARs with pruning: 3089\n",
      "CBA-RG's run time with pruning: 25.62 s\n",
      "CBA-CB M1's run time with pruning: 3.70 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 239\n",
      "\n",
      "Round 9:\n",
      "\n",
      "CBA's accuracy with pruning: 0.87\n",
      "CBA's f1-score with pruning: 0.88\n",
      "No. of CARs with pruning: 2897\n",
      "CBA-RG's run time with pruning: 26.09 s\n",
      "CBA-CB M1's run time with pruning: 3.45 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 236\n",
      "\n",
      "Average CBA's accuracy with pruning: 0.88\n",
      "Average CBA's f1-score with pruning: 0.87\n",
      "Average No. of CARs with pruning: 3269\n",
      "Average CBA-RG's run time with pruning: 26.386 s\n",
      "Average CBA-CB M1's run time with pruning: 3.838 s\n",
      "Average No. of rules in classifier of CBA-CB M1 with pruning: 241\n",
      "Classifying Mushroom dataset\n",
      "\n",
      "Round 0:\n",
      "\n",
      "CBA's accuracy with pruning: 1.0\n",
      "CBA's f1-score with pruning: 1.0\n",
      "No. of CARs with pruning: 7516\n",
      "CBA-RG's run time with pruning: 62.61 s\n",
      "CBA-CB M1's run time with pruning: 0.38 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 23\n",
      "\n",
      "Round 1:\n",
      "\n",
      "CBA's accuracy with pruning: 1.0\n",
      "CBA's f1-score with pruning: 1.0\n",
      "No. of CARs with pruning: 12217\n",
      "CBA-RG's run time with pruning: 65.96 s\n",
      "CBA-CB M1's run time with pruning: 0.45 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 23\n",
      "\n",
      "Round 2:\n",
      "\n",
      "CBA's accuracy with pruning: 1.0\n",
      "CBA's f1-score with pruning: 1.0\n",
      "No. of CARs with pruning: 18411\n",
      "CBA-RG's run time with pruning: 108.36 s\n",
      "CBA-CB M1's run time with pruning: 0.66 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 23\n",
      "\n",
      "Round 3:\n",
      "\n",
      "CBA's accuracy with pruning: 1.0\n",
      "CBA's f1-score with pruning: 1.0\n",
      "No. of CARs with pruning: 15648\n",
      "CBA-RG's run time with pruning: 99.48 s\n",
      "CBA-CB M1's run time with pruning: 0.42 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 22\n",
      "\n",
      "Round 4:\n",
      "\n",
      "CBA's accuracy with pruning: 1.0\n",
      "CBA's f1-score with pruning: 1.0\n",
      "No. of CARs with pruning: 16497\n",
      "CBA-RG's run time with pruning: 92.52 s\n",
      "CBA-CB M1's run time with pruning: 0.41 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 22\n",
      "\n",
      "Round 5:\n",
      "\n",
      "CBA's accuracy with pruning: 1.0\n",
      "CBA's f1-score with pruning: 1.0\n",
      "No. of CARs with pruning: 15582\n",
      "CBA-RG's run time with pruning: 91.16 s\n",
      "CBA-CB M1's run time with pruning: 0.30 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 22\n",
      "\n",
      "Round 6:\n",
      "\n",
      "CBA's accuracy with pruning: 1.0\n",
      "CBA's f1-score with pruning: 1.0\n",
      "No. of CARs with pruning: 18924\n",
      "CBA-RG's run time with pruning: 108.76 s\n",
      "CBA-CB M1's run time with pruning: 0.40 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 23\n",
      "\n",
      "Round 7:\n",
      "\n",
      "CBA's accuracy with pruning: 1.0\n",
      "CBA's f1-score with pruning: 1.0\n",
      "No. of CARs with pruning: 17454\n",
      "CBA-RG's run time with pruning: 98.18 s\n",
      "CBA-CB M1's run time with pruning: 1.00 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 22\n",
      "\n",
      "Round 8:\n",
      "\n",
      "CBA's accuracy with pruning: 1.0\n",
      "CBA's f1-score with pruning: 1.0\n",
      "No. of CARs with pruning: 16341\n",
      "CBA-RG's run time with pruning: 105.19 s\n",
      "CBA-CB M1's run time with pruning: 0.42 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 21\n",
      "\n",
      "Round 9:\n",
      "\n",
      "CBA's accuracy with pruning: 1.0\n",
      "CBA's f1-score with pruning: 1.0\n",
      "No. of CARs with pruning: 16379\n",
      "CBA-RG's run time with pruning: 109.39 s\n",
      "CBA-CB M1's run time with pruning: 0.49 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 21\n",
      "\n",
      "Average CBA's accuracy with pruning: 1.0\n",
      "Average CBA's f1-score with pruning: 1.0\n",
      "Average No. of CARs with pruning: 15496\n",
      "Average CBA-RG's run time with pruning: 94.160 s\n",
      "Average CBA-CB M1's run time with pruning: 0.491 s\n",
      "Average No. of rules in classifier of CBA-CB M1 with pruning: 22\n",
      "Classifying Diabetes dataset\n",
      "\n",
      "Round 0:\n",
      "\n",
      "CBA's accuracy with pruning: 0.94\n",
      "CBA's f1-score with pruning: 0.95\n",
      "No. of CARs with pruning: 7156\n",
      "CBA-RG's run time with pruning: 30.48 s\n",
      "CBA-CB M1's run time with pruning: 0.12 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 47\n",
      "\n",
      "Round 1:\n",
      "\n",
      "CBA's accuracy with pruning: 1.0\n",
      "CBA's f1-score with pruning: 1.0\n",
      "No. of CARs with pruning: 8424\n",
      "CBA-RG's run time with pruning: 37.57 s\n",
      "CBA-CB M1's run time with pruning: 0.10 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 42\n",
      "\n",
      "Round 2:\n",
      "\n",
      "CBA's accuracy with pruning: 0.96\n",
      "CBA's f1-score with pruning: 0.97\n",
      "No. of CARs with pruning: 6364\n",
      "CBA-RG's run time with pruning: 33.30 s\n",
      "CBA-CB M1's run time with pruning: 0.12 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 42\n",
      "\n",
      "Round 3:\n",
      "\n",
      "CBA's accuracy with pruning: 0.92\n",
      "CBA's f1-score with pruning: 0.93\n",
      "No. of CARs with pruning: 6326\n",
      "CBA-RG's run time with pruning: 31.10 s\n",
      "CBA-CB M1's run time with pruning: 0.14 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 44\n",
      "\n",
      "Round 4:\n",
      "\n",
      "CBA's accuracy with pruning: 1.0\n",
      "CBA's f1-score with pruning: 1.0\n",
      "No. of CARs with pruning: 4877\n",
      "CBA-RG's run time with pruning: 26.70 s\n",
      "CBA-CB M1's run time with pruning: 0.21 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 46\n",
      "\n",
      "Round 5:\n",
      "\n",
      "CBA's accuracy with pruning: 0.92\n",
      "CBA's f1-score with pruning: 0.94\n",
      "No. of CARs with pruning: 5648\n",
      "CBA-RG's run time with pruning: 25.57 s\n",
      "CBA-CB M1's run time with pruning: 0.13 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 43\n",
      "\n",
      "Round 6:\n",
      "\n",
      "CBA's accuracy with pruning: 0.9\n",
      "CBA's f1-score with pruning: 0.92\n",
      "No. of CARs with pruning: 7874\n",
      "CBA-RG's run time with pruning: 34.16 s\n",
      "CBA-CB M1's run time with pruning: 0.08 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 40\n",
      "\n",
      "Round 7:\n",
      "\n",
      "CBA's accuracy with pruning: 0.96\n",
      "CBA's f1-score with pruning: 0.97\n",
      "No. of CARs with pruning: 8443\n",
      "CBA-RG's run time with pruning: 38.48 s\n",
      "CBA-CB M1's run time with pruning: 0.12 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 41\n",
      "\n",
      "Round 8:\n",
      "\n",
      "CBA's accuracy with pruning: 1.0\n",
      "CBA's f1-score with pruning: 1.0\n",
      "No. of CARs with pruning: 5989\n",
      "CBA-RG's run time with pruning: 26.47 s\n",
      "CBA-CB M1's run time with pruning: 0.14 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 45\n",
      "\n",
      "Round 9:\n",
      "\n",
      "CBA's accuracy with pruning: 0.98\n",
      "CBA's f1-score with pruning: 0.98\n",
      "No. of CARs with pruning: 6526\n",
      "CBA-RG's run time with pruning: 30.95 s\n",
      "CBA-CB M1's run time with pruning: 0.15 s\n",
      "No. of rules in classifier of CBA-CB M1 with pruning: 41\n",
      "\n",
      "Average CBA's accuracy with pruning: 0.96\n",
      "Average CBA's f1-score with pruning: 0.97\n",
      "Average No. of CARs with pruning: 6762\n",
      "Average CBA-RG's run time with pruning: 31.478 s\n",
      "Average CBA-CB M1's run time with pruning: 0.132 s\n",
      "Average No. of rules in classifier of CBA-CB M1 with pruning: 43\n"
     ]
    }
   ],
   "source": [
    "dataset_funcs = [German, Australian, Crx, Hepatitis, Ionosphere, Pumpkin, Mushroom, Diabetes]\n",
    "stats_list = {'dataset':[], 'accuracy':[], 'f1_score':[], 'CBA_count':[], 'CBA_RG_runtime':[], 'CBA_CB_runtime':[], 'rule_count':[] }\n",
    "for dataset_getter in dataset_funcs:\n",
    "    print(f\"Classifying {dataset_getter.__name__} dataset\")\n",
    "    avg_acc, avg_f1, avg_car_cnt, avg_rg_runtime, avg_cb_runtime, avg_rule_cnt = cross_validate_m1(dataset_getter().values.tolist(), quiet=False)\n",
    "    stats_list['dataset'].append(dataset_getter.__name__)\n",
    "    stats_list['accuracy'].append(avg_acc)\n",
    "    stats_list['f1_score'].append(avg_f1)\n",
    "    stats_list['CBA_count'].append(avg_car_cnt)\n",
    "    stats_list['CBA_RG_runtime'].append(avg_rg_runtime)\n",
    "    stats_list['CBA_CB_runtime'].append(avg_cb_runtime)\n",
    "    stats_list['rule_count'].append(avg_rule_cnt)\n",
    "pd.DataFrame(stats_list).to_csv(os.path.join(OUTPUT, 'CBA_results.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7af7df4901773a0e355da496bf365ae011b1b331a57bbc9908dae1ee21823d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
